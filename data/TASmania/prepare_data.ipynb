{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3e73137b-2ffc-4639-8b50-1163359651fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "def find_toxin_antitoxin_pairs(file_path):\n",
    "    \"\"\"\n",
    "    Find toxin-antitoxin pairs within the same operon from TSV data.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the TSV file\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries containing TA pair information\n",
    "    \"\"\"\n",
    "    # Read the TSV file\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    # Filter for rows that have TAS_info as 'T' or 'A'\n",
    "    tas_df = df[df['TAS_info'].isin(['T', 'A'])].copy()\n",
    "\n",
    "    # Group by operon_id\n",
    "    operon_groups = tas_df.groupby('operon_id')\n",
    "\n",
    "    ta_pairs = []\n",
    "\n",
    "    for operon_id, group in operon_groups:\n",
    "        # Get toxins and antitoxins in this operon\n",
    "        toxins = group[group['TAS_info'] == 'T']\n",
    "        antitoxins = group[group['TAS_info'] == 'A']\n",
    "\n",
    "        # Create pairs - each toxin with each antitoxin in the same operon\n",
    "        for _, toxin in toxins.iterrows():\n",
    "            for _, antitoxin in antitoxins.iterrows():\n",
    "                pair = {\n",
    "                    'operon_id': operon_id,\n",
    "                    'toxin_gene_id': toxin['ensembl_gene_id'],\n",
    "                    'toxin_description': toxin['gene_description'],\n",
    "                    'toxin_length': toxin['protein_length'],\n",
    "                    'toxin_start': toxin['start'],\n",
    "                    'toxin_end': toxin['end'],\n",
    "                    'antitoxin_gene_id': antitoxin['ensembl_gene_id'],\n",
    "                    'antitoxin_description': antitoxin['gene_description'],\n",
    "                    'antitoxin_length': antitoxin['protein_length'],\n",
    "                    'antitoxin_start': antitoxin['start'],\n",
    "                    'antitoxin_end': antitoxin['end'],\n",
    "                    'distance': abs(toxin['start'] - antitoxin['start']),\n",
    "                    'toxin_sequence': toxin['protein_sequence'],\n",
    "                    'antitoxin_sequence': antitoxin['protein_sequence']\n",
    "                }\n",
    "                ta_pairs.append(pair)\n",
    "\n",
    "    return ta_pairs\n",
    "\n",
    "def prepare_dataset_pairs(file_path, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create a dataframe with positive (same operon) and negative (different operon) TA pairs.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the TSV file\n",
    "        random_seed (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['protein1', 'protein2', 'label']\n",
    "    \"\"\"\n",
    "    import random\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Read the TSV file\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    \n",
    "    # Filter for rows that have TAS_info as 'T' or 'A'\n",
    "    tas_df = df[df['TAS_info'].isin(['T', 'A'])].copy()\n",
    "    \n",
    "    # Separate toxins and antitoxins\n",
    "    toxins = tas_df[tas_df['TAS_info'] == 'T'].copy()\n",
    "    antitoxins = tas_df[tas_df['TAS_info'] == 'A'].copy()\n",
    "    \n",
    "    labeled_pairs = []\n",
    "    \n",
    "    # 1. Create positive pairs (label = 1) - same operon\n",
    "    operon_groups = tas_df.groupby('operon_id')\n",
    "    \n",
    "    for operon_id, group in operon_groups:\n",
    "        operon_toxins = group[group['TAS_info'] == 'T']\n",
    "        operon_antitoxins = group[group['TAS_info'] == 'A']\n",
    "        \n",
    "        # Create pairs within the same operon\n",
    "        for _, toxin in operon_toxins.iterrows():\n",
    "            for _, antitoxin in operon_antitoxins.iterrows():\n",
    "                labeled_pairs.append({\n",
    "                    'protein1': toxin['ensembl_gene_id'],\n",
    "                    'protein2': antitoxin['ensembl_gene_id'],\n",
    "                    'label': 1\n",
    "                })\n",
    "    \n",
    "    # 2. Create negative pairs (label = 0) - different operons\n",
    "    # For each toxin, randomly assign an antitoxin from a different operon\n",
    "    for _, toxin in toxins.iterrows():\n",
    "        toxin_operon = toxin['operon_id']\n",
    "        \n",
    "        # Get antitoxins from different operons\n",
    "        different_operon_antitoxins = antitoxins[antitoxins['operon_id'] != toxin_operon]\n",
    "        \n",
    "        if not different_operon_antitoxins.empty:\n",
    "            # Randomly select one antitoxin from different operon\n",
    "            random_antitoxin = different_operon_antitoxins.sample(n=1).iloc[0]\n",
    "            \n",
    "            labeled_pairs.append({\n",
    "                'protein1': toxin['ensembl_gene_id'],\n",
    "                'protein2': random_antitoxin['ensembl_gene_id'],\n",
    "                'label': 0\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    pairs_df = pd.DataFrame(labeled_pairs)\n",
    "    \n",
    "    return pairs_df\n",
    "\n",
    "def save_sequences_to_fasta(file_path, output_fasta_path, pairs_df):\n",
    "    \"\"\"\n",
    "    Save unique sequences from the dataset pairs into a FASTA file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the TSV file with original data.\n",
    "        output_fasta_path (str): Path to save the FASTA file.\n",
    "        pairs_df (pd.DataFrame): DataFrame with protein1 and protein2 columns.\n",
    "    \"\"\"\n",
    "    # Read the original TSV file\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    # Get all unique gene IDs from the pairs\n",
    "    unique_gene_ids = pd.unique(pairs_df[['protein1', 'protein2']].values.ravel())\n",
    "\n",
    "    # Filter for rows with those gene IDs\n",
    "    sequence_df = df[df['ensembl_gene_id'].isin(unique_gene_ids)].drop_duplicates(subset='ensembl_gene_id')\n",
    "\n",
    "    # Create SeqRecord objects\n",
    "    records = []\n",
    "    for _, row in sequence_df.iterrows():\n",
    "        gene_id = row['ensembl_gene_id']\n",
    "        sequence = row['protein_sequence']  # Assumes the column is named 'sequence'\n",
    "        records.append(SeqRecord(Seq(sequence), id=gene_id, description=\"\"))\n",
    "\n",
    "    # Write to FASTA file\n",
    "    SeqIO.write(records, output_fasta_path, \"fasta\")\n",
    "\n",
    "def print_pairs_summary(ta_pairs):\n",
    "    \"\"\"Print a summary of found TA pairs.\"\"\"\n",
    "    print(f\"Found {len(ta_pairs)} toxin-antitoxin pairs\")\n",
    "    print(f\"Across {len(set(pair['operon_id'] for pair in ta_pairs))} operons\")\n",
    "    print(\"\\nPair details:\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for i, pair in enumerate(ta_pairs, 1):\n",
    "        print(f\"Pair {i}:\")\n",
    "        print(f\"  Operon: {pair['operon_id']}\")\n",
    "        print(f\"  Toxin: {pair['toxin_gene_id']} ({pair['toxin_description']}) - {pair['toxin_length']} aa\")\n",
    "        print(f\"  Antitoxin: {pair['antitoxin_gene_id']} ({pair['antitoxin_description']}) - {pair['antitoxin_length']} aa\")\n",
    "        print(f\"  Distance: {pair['distance']} bp\")\n",
    "        print()\n",
    "\n",
    "def save_data_to_csv(df, output_file):\n",
    "    \"\"\"Save TA pairs to CSV file.\"\"\"\n",
    "    df.to_csv(output_file, index=False, sep=\"\\t\")\n",
    "    print(f\"TA pairs saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45da7e77-5cd1-4d52-82c5-7c1879ffcd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table_path = \"/scicore/home/schwede/pudziu0000/projects/gLM/data/TASmania/mycobacterium_tuberculosis/mycobacterium_tuberculosis_h37rv_summary_table.tsv\"\n",
    "data_dir = \"/scicore/home/schwede/pudziu0000/projects/gLM/data/TASmania/mycobacterium_tuberculosis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2550e90a-ff74-42d6-ade4-408348ed1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_pairs = find_toxin_antitoxin_pairs(summary_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "199f52a5-7b18-4c3b-a499-a68a5d9718fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA pairs saved to /scicore/home/schwede/pudziu0000/projects/gLM/data/TASmania/mycobacterium_tuberculosis//test.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_dataset_pairs(summary_table_path, random_seed=42)\n",
    "save_sequences_to_fasta(summary_table_path, f\"{data_dir}/sequences.fasta\", dataset)\n",
    "save_data_to_csv(dataset, f\"{data_dir}/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61108c-da4e-4172-a957-9fae0bd8e76e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mambaforge-gLM11]",
   "language": "python",
   "name": "conda-env-mambaforge-gLM11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
