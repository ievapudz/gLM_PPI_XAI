seed_everything: 42
model:
    class_path: gLM.models.gLM2
    init_args:
        model: 
            class_path: gLM.models.EntropyFactors
            init_args:
                matrix_path: ./outputs/entropy_factors/
data:
    class_path: gLM.dataloader.SequencePairDataModule
    init_args:
        fasta_file: ./data/Bernett2022/human_swissprot_oneliner.fasta
        data_folder: ./data/Bernett2022/
        batch_size: 4096
        positive_only: false
        num_workers: 0
        num_samples: null
optimizer:
    class_path: torch.optim.Adam
    init_args:
        lr: 0.001
        weight_decay: 0.0001
trainer:
    max_epochs: 1
    deterministic: true
    logger:
        class_path: pytorch_lightning.loggers.WandbLogger
        init_args:
            save_dir: 'logs'
            offline: true
            project: gLM_PPI_XAI
            name: 'Bernett2022_1k_avg_entropy'
            log_model: false
            prefix: ''
    enable_checkpointing: true
    callbacks:
      - class_path: gLM.callbacks.SetupWandB 
      - class_path: gLM.callbacks.OutputLoggingCallback
        init_args:
            log_every_n_steps: 1
      - class_path: gLM.callbacks.LogClassificationMetrics
        init_args:
          class_names:
          - 'Negative'
          - 'Positive'
          y_pred_key: predictions
          y_pred_lab_key: predicted_label
          y_true_lab_key: label
          make_one_hot: true
          invert_probabilities: true
          make_correct_dim: true
          metrics_to_plot:
            - confusion_matrix
            - class_proportions
            - calibration_curves
            - classification_report
            - mcc
            - roc
      - class_path: pytorch_lightning.callbacks.ModelCheckpoint
        init_args:
            dirpath: logs/checkpoints/optimized/
            filename: model-{epoch}
            monitor: val/loss
            mode: min
            save_last: true
            save_top_k: 1




